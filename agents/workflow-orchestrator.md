<!--
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”§ MAINTENANCE REQUIRED                                                      â•‘
â•‘ After editing: CLAUDE.md, help, README, tests                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->

---
name: workflow-orchestrator
description: |
  **CONTRIBUTOR REFERENCE DOCUMENTATION**

  This file documents the workflow orchestration system architecture.
  It is NOT read by Claude during normal operation.

  Orchestration logic is EMBEDDED in user project CLAUDE.md files.
  This file explains how the system works for contributors/maintainers.

  See templates/project/CLAUDE.md.*.template for actual orchestration.
tools: N/A (reference documentation only)
---

# Workflow Orchestration System

**Purpose:** This document explains how the workflow orchestration system works for contributors and maintainers.

**Important (v3.1):** This is NOT operational documentation. Orchestration logic is in the **workflow skill** (`templates/skills/workflow/SKILL.md`), NOT in project CLAUDE.md files.

Project CLAUDE.md files are now minimal (~80 lines) and contain only state tracking.

---

## Architecture Overview

### Current Architecture (v3.1 - Skills + Hooks)

```
Skills (Domain Expertise)
   ~/.claude/skills/workflow/SKILL.md     â† Orchestration logic
   ~/.claude/skills/ux-design/SKILL.md    â† Design principles
   ~/.claude/skills/frontend/SKILL.md     â† Frontend expertise
   ~/.claude/skills/backend/SKILL.md      â† Backend patterns
   ... (9 skills total)
   â†“
   Loaded ON-DEMAND by Claude (automatic)
   â†“
Subagents (Isolated Tasks)
   ~/.claude/agents/code-reviewer.md      â† Isolated review
   ~/.claude/agents/debugger.md           â† Isolated debugging
   ~/.claude/agents/ui-debugger.md        â† Browser automation
   â†“
   Invoked via Task tool when needed
   â†“
Project CLAUDE.md (~80 lines)
   State only, minimal context
   â†“
Hooks (.claude/settings.json - optional)
   PostToolUse â†’ Quality reminders
   Stop â†’ Completion checklist
```

**Benefits:**
- 90% less upfront context (80 lines vs 750)
- Skills cached between sessions
- On-demand loading = better performance
- Modular and independently updatable

**Key Change:** Orchestration logic moved FROM project CLAUDE.md TO workflow skill.

### Previous Architectures (Historical Reference)

**v2.0 (Self-Contained Templates):**
- 750+ line CLAUDE.md with embedded orchestration
- Problem: Context bloat, poor performance
- Deprecated in v3.1

**v0.9-v1.0 (External Orchestrator):**
- HTML comment pointing to orchestrator.md
- Problem: Unreliable, could be ignored
- Deprecated in v2.0

```
Template: templates/project/CLAUDE.md.greenfield.template
   â†“
   Contains ALL orchestration logic embedded
   â†“
   workflow-init generates â†’ User Project CLAUDE.md
   â†“
   Self-contained, guaranteed to work âœ“
```

**Solution:** All orchestration logic embedded in templates. External agent files are optional reference documentation.

---

## Agent Coordination System

### All 15 Specialized Agents

The orchestration system coordinates these agents automatically:

#### L1 Analysis Agents (App Planning)
- **intent-guardian** - Define user promises with criticality levels
- **ux-architect** - Design user experience and design system
- **agentic-architect** - Design system architecture with promise mapping
- **implementation-planner** - Create build plans with validation tasks

#### L1 Support Agents
- **change-analyzer** - Assess impact when user requests changes/additions
- **gap-analyzer** - Find issues in brownfield (existing) codebases
- **brownfield-analyzer** - Initial scan of existing projects

#### L2 Building Agents (Feature Implementation)
- **backend-engineer** - Implement APIs, database, services
- **frontend-engineer** - Implement UI (follows design system)
- **test-engineer** - Write tests and verify implementations

#### L2 Support Agents
- **code-reviewer** - Review code quality, security, intent compliance
- **debugger** - Fix bugs and issues (backend/general)
- **ui-debugger** - Debug UI issues with browser automation
- **acceptance-validator** - Validate promises are kept (not just code working)

#### Operations Agent
- **project-ops** - Project setup, sync, docs, verification, AI integration

---

## Orchestration Flows

### Greenfield Flow (New Projects)

```
User describes project
   â†“
L1 Phase: Planning
   â”œâ”€â–º intent-guardian â†’ Create product-intent.md
   â”œâ”€â–º ux-architect â†’ Create user-journeys.md
   â”œâ”€â–º agentic-architect â†’ Create agent-design.md
   â””â”€â–º implementation-planner â†’ Create feature plans
   â†“
L2 Phase: Building
   For each feature:
      â”œâ”€â–º backend-engineer â†’ Implement backend
      â”‚   â”œâ”€â–º code-reviewer (MANDATORY)
      â”‚   â””â”€â–º Run tests (MANDATORY)
      â”œâ”€â–º frontend-engineer â†’ Implement frontend
      â”‚   â”œâ”€â–º code-reviewer (MANDATORY)
      â”‚   â”œâ”€â–º Run tests (MANDATORY)
      â”‚   â””â”€â–º ui-debugger (if available)
      â”œâ”€â–º test-engineer â†’ Write comprehensive tests
      â”‚   â””â”€â–º Run ALL tests (MANDATORY)
      â””â”€â–º acceptance-validator â†’ Validate promises KEPT
          â”œâ”€â–º CI verification
          â”œâ”€â–º Update docs
          â””â”€â–º Feature COMPLETE
```

### Brownfield Flow (Existing Codebases)

```
First session
   â†“
brownfield-analyzer â†’ Scan codebase
   â”œâ”€â–º Detect tech stack
   â”œâ”€â–º Identify features
   â”œâ”€â–º Infer promises
   â””â”€â–º Estimate test coverage
   â†“
Create [INFERRED] documentation
   â”œâ”€â–º docs/intent/product-intent.md
   â”œâ”€â–º docs/architecture/system-design.md
   â””â”€â–º docs/plans/current-state.md
   â†“
Ask user what to do:
   â”œâ”€â–º Add feature â†’ change-analyzer â†’ L2 flow
   â”œâ”€â–º Improve code â†’ gap-analyzer â†’ Fix gaps
   â”œâ”€â–º Fix bug â†’ debugger â†’ Fix + test
   â””â”€â–º Something else
```

### Gap Analysis Flow

```
User requests /gap or "improve codebase"
   â†“
gap-analyzer
   â”œâ”€â–º Compare current vs ideal
   â”œâ”€â–º Categorize gaps (Critical/High/Medium/Low)
   â””â”€â–º Create migration plan with phases
   â†“
For each gap (by priority):
   â”œâ”€â–º Invoke appropriate engineer agent
   â”œâ”€â–º Apply fix
   â”œâ”€â–º code-reviewer (MANDATORY)
   â”œâ”€â–º Add regression test (MANDATORY)
   â””â”€â–º Mark gap complete
```

### Change Request Flow

```
User says "add [feature]"
   â†“
change-analyzer
   â”œâ”€â–º Analyze impact on intent/architecture/plans
   â”œâ”€â–º Estimate effort and complexity
   â”œâ”€â–º Identify dependencies and risks
   â””â”€â–º Present analysis
   â†“
User confirms
   â†“
Update documentation
   â”œâ”€â–º Add promises to intent doc
   â”œâ”€â–º Update architecture if needed
   â””â”€â–º Create feature plan
   â†“
Continue to L2 building for feature
```

### UI Testing Flow (LLM User Testing)

```
Trigger: Frontend implementation complete + UI deployed
   â†“
Detect UI readiness
   â”œâ”€â–º Check: L1 docs exist (intent, UX, architecture)
   â”œâ”€â–º Check: UI is accessible (localhost/staging/prod)
   â””â”€â–º Check: No blocking test failures
   â†“
Suggest: "UI is ready for LLM user testing. Run /llm-user init?"
   â†“
User confirms
   â†“
Load llm-user-testing skill
   â”œâ”€â–º Phase 1: Analyze docs
   â”‚   â”œâ”€â–º Extract promises from product-intent.md
   â”‚   â”œâ”€â–º Extract personas from user-journeys.md
   â”‚   â”œâ”€â–º Extract acceptance criteria from plans
   â”‚   â””â”€â–º Extract domain knowledge from architecture
   â”œâ”€â–º Phase 2: Synthesize test-spec.yaml
   â”‚   â”œâ”€â–º Create evaluation rubric
   â”‚   â”œâ”€â–º Define success thresholds
   â”‚   â””â”€â–º Map promises to test scenarios
   â”œâ”€â–º Phase 3: Generate infrastructure
   â”‚   â”œâ”€â–º Create project-specific {{project}}-llm-user.md
   â”‚   â”œâ”€â–º Create project-specific {{project}}-evaluator.md
   â”‚   â”œâ”€â–º Generate persona YAML files
   â”‚   â””â”€â–º Generate scenario YAML files
   â”œâ”€â–º Phase 4: Present for review
   â”‚   â”œâ”€â–º Show: 3 personas generated
   â”‚   â”œâ”€â–º Show: 5 scenarios created
   â”‚   â”œâ”€â–º Show: Evaluation criteria
   â”‚   â””â”€â–º Ask: "Review test-spec.yaml and iterate if needed?"
   â””â”€â–º Phase 5: Ready to test
       â””â”€â–º Suggest: "Run /test-ui --url=<URL> to execute tests"
   â†“
User reviews evaluation criteria
   â”œâ”€â–º If needs changes: Edit test-spec.yaml â†’ /llm-user refresh
   â””â”€â–º If approved: Continue
   â†“
Execute UI tests
   â”œâ”€â–º Invoke /test-ui command
   â”œâ”€â–º For each scenario:
   â”‚   â”œâ”€â–º Spawn LLM user with persona
   â”‚   â”œâ”€â–º Execute user journey steps
   â”‚   â”œâ”€â–º Record interactions + screenshots
   â”‚   â””â”€â–º Track frustration/motivation dynamics
   â”œâ”€â–º Invoke evaluator
   â”‚   â”œâ”€â–º Score promise fulfillment
   â”‚   â”œâ”€â–º Identify gaps with severity
   â”‚   â””â”€â–º Generate recommendations
   â””â”€â–º Present results
       â”œâ”€â–º Overall score (e.g., 7.2/10)
       â”œâ”€â–º Promise status (validated/partial/failed)
       â”œâ”€â–º Critical gaps (release blockers)
       â””â”€â–º Suggest: "/llm-user gaps for details"
   â†“
Handle results
   â”œâ”€â–º If critical gaps: Load gap-resolver skill â†’ Suggest "/fix-gaps --priority=critical"
   â”œâ”€â–º If high priority gaps: Load gap-resolver skill â†’ Suggest "/fix-gaps --priority=high"
   â”œâ”€â–º If medium/low gaps: Log for future improvement â†’ Suggest "/fix-gaps list"
   â””â”€â–º Update promise status in CLAUDE.md state
   â†“
Gap-driven development cycle (with gap-resolver skill)
   1. /fix-gaps â†’ Systematic gap resolution
      â”œâ”€â–º Prioritize gaps by severity
      â”œâ”€â–º Create fix specification
      â”œâ”€â–º Implement via workflow agents
      â””â”€â–º Verify with re-testing
   2. /fix-gaps verify â†’ Re-run failed scenarios
      â””â”€â–º Compare before/after results
   3. /fix-gaps status â†’ Track progress
   4. /fix-gaps report â†’ Generate improvement report
```

**Integration Points:**

1. **After frontend-engineer completes** â†’ Check if UI accessible â†’ Suggest `/llm-user init`
2. **Before acceptance-validator** â†’ Run LLM user tests first (automated validation)
3. **After test results** â†’ If gaps found â†’ Load gap-resolver skill â†’ Suggest `/fix-gaps`
4. **After gaps fixed** â†’ Suggest `/fix-gaps verify` to re-run failed scenarios
5. **When docs change** â†’ Remind user to run `/llm-user refresh`

**Keywords that trigger LLM user testing:**
- "UI is ready", "frontend done", "deployed to staging"
- "test the user experience", "validate user journeys"
- "check if promises work in UI"

**Keywords that trigger gap resolution:**
- "fix the gaps", "resolve issues found", "improve test scores"
- "critical gaps", "high priority issues"
- "validate promises", "close gaps"

---

## Quality Gates (Automatic Enforcement)

### After Code Changes

**Trigger:** Any file in `src/`, `lib/`, `app/`, etc. created or modified

**Action:**
1. Invoke code-reviewer on changed files
2. If issues: Show, ask to fix
3. If clean: Continue silently

### After Backend/Frontend Steps

**Trigger:** Engineer agent completes

**Action:**
1. code-reviewer on new/modified files (MANDATORY)
2. Run relevant tests (MANDATORY)
3. If fail: invoke debugger, fix, retry
4. If pass: continue

### After Testing Step

**Trigger:** test-engineer completes

**Action:**
1. Run FULL test suite (MANDATORY)
2. All must pass
3. If failures: STOP, fix, retry

### After Feature Complete

**Trigger:** All steps pass

**Action:**
1. LLM User Testing (if UI exists)
   - Check: UI accessible + L1 docs exist
   - Suggest: /llm-user init (if not done)
   - Execute: /test-ui to validate user journeys
   - If critical gaps: STOP, fix, re-test
   - If high priority gaps: Recommend fixing
   - Update promise status based on test results
2. Promise Validation (CRITICAL)
   - acceptance-validator (manual validation)
   - If PARTIAL/FAILED: fix and re-validate
   - If VALIDATED: continue
3. CI Verification
   - scripts/verify.sh if exists
   - lint/typecheck if configured
4. Documentation
   - project-ops sync
   - Update intent doc
   - Update CLAUDE.md state

---

## State Tracking

State is maintained in YAML block in user project CLAUDE.md:

```yaml
workflow:
  version: 1.0
  type: greenfield|brownfield
  phase: L1|L2|analysis
  status: not_started|in_progress|paused|complete
  mode: auto|manual

l1:
  intent: { status, output }
  ux: { status, output }
  architecture: { status, output }
  planning: { status, output }

l2:
  current_feature: string
  current_step: backend|frontend|testing|verification
  features: { [name]: { status, backend, frontend, tests, verification, promises } }

promises:
  # PRM-001:
  #   statement: "..."
  #   criticality: CORE|IMPORTANT|NICE_TO_HAVE
  #   status: pending|validated|partial|failed
  #   implementing_features: [...]

quality:
  last_review: timestamp
  last_review_result: pass|fail
  last_test_run: timestamp
  last_test_result: pass|fail

session:
  last_updated: timestamp
  last_action: string
  next_action: string
```

---

## Issue Detection and Response

### Keyword Triggers

| Keywords | Agent Invoked |
|----------|---------------|
| "doesn't work", "broken", "bug", "error", "crash", "exception" | **debugger** |
| "page", "screen", "button", "UI", "display", "layout", "click" + issue | **ui-debugger** |
| "test failing", "tests broken", "spec failed" | **debugger** + **test-engineer** |
| "add [feature]", "also need", "change [thing]" | **change-analyzer** |
| "/gap", "/audit", "improve codebase", "fix tech debt" | **gap-analyzer** |
| "UI is ready", "frontend done", "deployed to staging", "test user journeys" | Load `llm-user-testing` skill â†’ `/llm-user init` |
| "validate user experience", "check if promises work in UI" | `/test-ui` |
| "fix the gaps", "resolve issues", "critical gaps", "validate promises" | Load `gap-resolver` skill â†’ `/fix-gaps` |
| "verify fixes", "re-test", "check improvements" | `/fix-gaps verify` |

### Response Protocols

All issue responses follow this pattern:
1. Acknowledge issue
2. Invoke appropriate debugger agent
3. Diagnose root cause
4. Apply fix
5. Add regression test (if applicable)
6. Verify fix with tests
7. code-reviewer on changes (MANDATORY)
8. Update state
9. Announce fix with explanation

---

## Template System

### Template Locations

- `templates/project/CLAUDE.md.greenfield.template` - New projects
- `templates/project/CLAUDE.md.brownfield.template` - Existing codebases

### Template Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `{{PROJECT_NAME}}` | Project name | "my-app" |
| `{{PROJECT_DESCRIPTION}}` | Brief description | "Spanish learning app" |
| `{{DATE}}` | Initialization date | "2026-01-26" |
| `{{WORKFLOW_HOME}}` | Workflow agents directory | "~/.claude-workflow-agents" |

### How Templates Work

1. User runs `workflow-init` in their project directory
2. Script detects if project is greenfield or brownfield
3. Script selects appropriate template
4. Script replaces `{{VARIABLES}}` with actual values
5. Script generates `CLAUDE.md` in user project root
6. User project now has self-contained orchestration

### When to Update Templates

**Update templates when:**
- Adding/removing agents
- Changing orchestration flows
- Modifying quality gates
- Adding new features to workflow system

**After updating templates:**
1. Run `./scripts/verify-docs.sh` to ensure sync
2. Test with `workflow-init` in a test directory
3. Update this file (workflow-orchestrator.md) with changes
4. Update CLAUDE.md (repo documentation) with changes

---

## Design Principles

### 1. Self-Containment

**Rule:** User project CLAUDE.md must contain ALL operational logic.

**Why:** External files can't be reliably read by Claude. HTML comments can be ignored.

**Implementation:** Embed full orchestration flows in templates.

### 2. Automatic Agent Chaining

**Rule:** User should never manually invoke agents.

**Why:** Reduces cognitive load, ensures consistency, improves developer experience.

**Implementation:** Keyword triggers and phase completion signals auto-invoke next agent.

### 3. Mandatory Quality Gates

**Rule:** code-reviewer and tests run after EVERY code change.

**Why:** Catches issues early, maintains code quality, validates promises.

**Implementation:** MANDATORY checkpoints in L2 flow that cannot be skipped.

### 4. Promise-Based Validation

**Rule:** Features aren't complete until promises are VALIDATED.

**Why:** Tests passing â‰  promises kept. Need explicit validation.

**Implementation:** acceptance-validator runs after all tests pass, validates actual user promises.

### 5. State Transparency

**Rule:** CLAUDE.md state must always reflect current progress.

**Why:** Enables session resumption, tracks progress, provides visibility.

**Implementation:** State updated after every significant action.

---

## Contributor Guidelines

### Adding a New Agent

1. Create agent file in `agents/[name].md`
2. Add to appropriate category (L1/L2/Support/Operations)
3. Update templates:
   - Add to "Agents Available" table
   - Add trigger keywords if applicable
   - Add to appropriate flow if primary agent
4. Update verification:
   - Add to `scripts/verify-docs.sh` COORDINATED_AGENTS array
   - Add to `tests/structural/test_agents_exist.sh`
5. Update repository docs:
   - Add to `CLAUDE.md` maintenance section
   - Add to `README.md` agents table
   - Add to `commands/help.md`
   - Add to `STATE.md`
6. Run `./scripts/verify-docs.sh` to verify sync
7. Commit all changes together

### Modifying Orchestration Flows

1. Update templates (greenfield and/or brownfield)
2. Update this file (workflow-orchestrator.md) to document changes
3. Update `CLAUDE.md` (repo) if needed
4. Test with `workflow-init` in a test directory
5. Verify Claude follows new flow correctly
6. Run `./scripts/verify-docs.sh`
7. Commit

### Testing Orchestration Changes

```bash
# Create test directory
mkdir /tmp/workflow-test-greenfield
cd /tmp/workflow-test-greenfield

# Initialize workflow
workflow-init

# Check generated CLAUDE.md
cat CLAUDE.md

# Verify orchestration logic is embedded
grep -A 10 "## L1 Orchestration Flow" CLAUDE.md

# Test with Claude Code (manually)
# Verify auto-chaining works as expected
```

---

## FAQ for Contributors

### Q: Why not just improve the old HTML comment approach?

**A:** Claude Code doesn't auto-read external files. HTML comments are not enforced and can be easily ignored. Self-contained templates guarantee Claude has the orchestration logic.

### Q: Won't this make templates harder to maintain?

**A:** Templates are larger (750+ lines vs 340), but:
- Easier to debug (all logic in one place)
- More reliable (no external dependencies)
- Better user experience (actually works!)
- Simpler mental model (no "wishful thinking")

### Q: What's the role of agents/*.md files now?

**A:** Reference documentation for:
- Contributors understanding agent capabilities
- Customization (users can read for detailed prompts)
- Debugging agent invocations
- System maintenance

### Q: How do changes propagate to user projects?

**A:** Users run `workflow-update` which:
1. Checks for new template version
2. Merges orchestration changes into their CLAUDE.md
3. Preserves their project-specific state/notes
4. Shows diff before applying

### Q: Can users customize the orchestration?

**A:** Yes! They can edit their CLAUDE.md directly. It's their file. The template is just a starting point. However, they should understand what they're changing.

### Q: How do we version orchestration changes?

**A:** `workflow.version` in state YAML tracks version. When templates change:
1. Increment version
2. Document breaking changes
3. Create migration guide if needed
4. `workflow-update` handles migration

---

## Related Files

- `templates/project/CLAUDE.md.greenfield.template` - Greenfield orchestration (source of truth)
- `templates/project/CLAUDE.md.brownfield.template` - Brownfield orchestration (source of truth)
- `CLAUDE.md` - Repository maintenance documentation
- `scripts/verify-docs.sh` - Documentation sync verification (includes orchestrator check)
- `commands/help.md` - In-app help system

---

## Version History

### v3.1 (2026-01-27)
- **Breaking Change:** Skills + Hooks architecture
- Orchestration logic moved FROM CLAUDE.md TO workflow skill
- 11 skills loaded on-demand by Claude
- Only 3 subagents (isolated tasks)
- Minimal CLAUDE.md (~80 lines, state only)
- Optional hooks for automatic quality gates
- 90% reduction in upfront context
- Better performance and modularity

### v2.0 (2026-01-26)
- **Breaking Change:** Self-contained CLAUDE.md templates (750+ lines)
- All orchestration embedded in project CLAUDE.md
- Deprecated in v3.1 due to context bloat

### v1.0 / v0.9 (Historical)
- External orchestrator file with HTML comment
- Unreliable (could be ignored)
- Deprecated in v2.0

